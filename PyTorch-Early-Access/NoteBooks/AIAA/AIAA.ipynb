{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "# AI Assisted Annotation \n\nManual annotation is slow, tediousÂ and costly. Faster labeling of 3D volumes using AI annotation models accelerates this process. Clara Train offers an AIAA API that easily integrates into common medical imaging viewers\n\u003cbr\u003e\u003cimg src\u003d\"screenShots/AIAASpeedup.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e\n\nAIAA is based on a server client model as shown below \n\u003cbr\u003e\u003cimg src\u003d\"screenShots/AIAAClientServer.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "By the end of this notebook you will be able to:\n",
        "- Start AIAA server \n",
        "- Load a deep grow model\n",
        "- Annotate using deep grow \n",
        "- Load your model and use it for annotations  \n",
        "- Stop AIAA server\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## Prerequisites\n",
        "- Nvidia GPU with 8Gb of memory   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "### Resources\nIt might be helpful to watch the GTC Digital 2021 talk on Clara Train SDK\n- [Clara Train 4.0 - 101 Getting Started [SE2688]](https://gtc21.event.nvidia.com/media/Clara%20Train%204.0%20-%20101%20Getting%20Started%20%5BSE2688%5D/1_0qgfrql2) \nClara train Getting started: cover basics, BYOC, AIAA, AutoML \n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "# Lets get started"
    },
    {
      "cell_type": "markdown",
      "source": "To interact with AIAA from the command line you should use the AIAA as `AIAA -h`. \nThis would show you all commands as shown below\n```\nUsage: AIAA [-h] {start,stop,status,list,load,delete} ...\n\ncommands:\n  start   Start AIAA Server\n          AIAA start -h\n  stop    Stop AIAA Server\n  status  Check if AIAA Server is running\n  list    List all models loaded in AIAA\n  logs    Fetch AIAA Logs if server is running \u003clines\u003e\n  load    Load a model to AIAA using one of the sources {ngc|mmar|zip|config}\n          sources:\n            ngc      Load model from NGC\n                     AIAA load \u003cmodel\u003e ngc \u003cpath\u003e \u003cversion\u003e\n            mmar     Load model from MMAR Folder\n                     AIAA load \u003cmodel\u003e mmar \u003cpath\u003e\n            zip      Load model from ZIP Archive\n                     AIAA load \u003cmodel\u003e zip \u003cpath\u003e\n            config   Load model using AIAA Config and Model saved file\n                     AIAA load \u003cmodel\u003e config \u003caiaa_config\u003e \u003csaved_model\u003e\n            pipeline Load pipeline (as vitual model) using AIAA Config\n                     AIAA load \u003cmodel\u003e config \u003caiaa_config\u003e\n  delete  Delete a model from AIAA\n          AIAA delete \u003cmodel\u003e\n```",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Before we get started let us check that we have an NVIDIA GPU available in the docker by running the cell below",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# following command should show all gpus available \n!nvidia-smi",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "\n# 1. Start AIAA server\nFirst lets set up AIAA path and change some permissions "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "AIAA_ROOT\u003d\"/claraDevDay/AIAA/workspace/\"\nAIAA_PORT\u003d\"5000\"\n!mkdir -p $AIAA_ROOT\n!chmod 777 $AIAA_ROOT\nprint (\"AIAA_ROOT is set to \",AIAA_ROOT)\n"
    },
    {
      "cell_type": "markdown",
      "source": "##  1.2 AIAA Server with Triton BackEnd \nStarting V4 Triton server was moved out of the clara train container. \nIn order to use Triton as the AIAA backend, you should use `restartClaraTrain.sh`. \nThe script uses docker-compose to start both the clara train container and triton container, \nwhile connected them through the docker internal network. \n\nNow lets start the AIAA server by running the cell below",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! AIAA start -b -w $AIAA_ROOT --engine TRITON --triton_ip tritonserver",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "# 2 Check on AIAA Server "
    },
    {
      "cell_type": "markdown",
      "source": "## 2.1 using CLI\nYou should check on the AIAA status",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!AIAA status   ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "You can also get the last 15 lines of the logs use",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!AIAA logs 15 ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "You can then easily filter on errors as  ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!AIAA logs |grep errors",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "To list models you can run ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!AIAA list",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n### 2.2 Using Browser\nYou can also check on the AIAA server using your browser by checking:\n- Main url `http://localhost:5000/` \u003cbr\u003e\n- APIS to list, upload, delete models `http://localhost:5000/docs/`\n- Check logs `http://localhost:5000/logs`\n- List available models `http://localhost:5000/v1/models/` \n ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 2.3 (For advanced users) Using curl commands\nYou can also use curl command to do list logs \nThe cell below will get the last 15 lines of the logs. ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "http_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/logs/?lines\u003d15\"\n!curl -X GET $http_str -H \"accept: application/json\" ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "To list models",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "http_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/v1/models\"\n!curl -X GET $http_str -H \"accept: application/json\"",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": "#  3. Load models in AIAA Server. \nFor this notebook we can download models from [NGC](). Models on NGC are either:\n- Annotation Models \u003cbr\u003e\n[Deep Extreme Cut: From Extreme Points to Object Segmentation](https://arxiv.org/abs/1711.09081)\n\u003cbr\u003e\u003cimg src\u003d\"screenShots/AIAAAnnotation.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e\n\n- Segmentation Models\n- DeepGrow MMAR \nThis is an interactive model to get you started with annotation. CNN takes in single channel (image) + use single click \nfor foreground or background location then produces the segmentation. it is based on [Interactive segmentation of medical images through\nfully convolution neural networks](https://arxiv.org/pdf/1903.08205.pdf)\n\u003cbr\u003e\u003cimg src\u003d\"screenShots/AIAADeepGrow.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "## 3.0 Loading options\nIn order to load a model to AIAA we will use the AIAA cli as "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! AIAA load -h",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "This will show you options which allows to load from ngc or a local MMAR or a local zip file, etc \n```\nroot@claratrain:/claraDevDay/AIAA# AIAA load -h\nLoading Model: -h\nUsage: AIAA load \u003cmodel\u003e {ngc|mmar|zip|config|pipeline} ...\n```",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 3.1 Load model trained from Getting started notebook\nIn order to load model trained in the getting started notebook you can run",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "modelName\u003d\"Test\"\nmodelFolderPath\u003d\"/claraDevDay/GettingStarted/models/config_train_Unet/model.ts\"\nconfigFolderPath\u003d\"/claraDevDay/GettingStarted/config/config_aiaa.json\"\n!AIAA load $modelName config $configFolderPath $modelFolderPath \n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 3.2 Using NGC CLI to download model from NGC (Will NOT work for EA) \nYou can see a [list of available pre-trained models](https://ngc.nvidia.com/containers/nvidia:clara-train-sdk) on NGC. \nYou can also use `ngc registry model list nvidia/med/clara_*` to get a list of models.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "!ngc registry model list nvidia/clara_*\n!ngc registry model list nvidia/med/clara_*\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": "The cell below will download the the deep grow model from NGC\n***Will Not work for EA***"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "The following cell will download the spleen model and load it into the AIAA server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "## 3.3 Manually Download model from NGC \nIf you have a private registry or have early access (EA) to nvidia\u0027s developer program, \nyou can manually downloaded the MMAR form NGC by clicking the ... button as shown below\n\u003cbr\u003e\u003cimg src\u003d\"screenShots/DownloadFromNGC.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e\n\n**You should download zip file to /claraDevDay/AIAA/DownloadsFromNGC/**\n \n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "## 3.4 This section should be deleted / updated Check for models loaded into AIAA\nZip file would have the MMAR structure. \nCell below would unzip the MMAR then upload it to AIAA server "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "downloadedFile\u003d\"GA_deepgrow_3d.zip\"\n\ndownloadDir\u003dAIAA_ROOT+\"../DownloadsFromNGC/\"\nmodelName\u003ddownloadedFile[:-4]\nmodelFolderPath\u003ddownloadDir+modelName\n\n%cd $downloadDir\n!unzip $downloadedFile -d $modelName",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!AIAA load $modelName mmar $modelFolderPath\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 3.5 load a pipeline created from multiple models into AIAA\nAIAA now supports the concept of a pipelines which triggers multiple models one at a time.\ncell below creates a pipeline out of 3D deepgrow which gets new seed points for multiple runs of deepgrow 2D.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "modelName\u003d\"GA_Deepgrow_Pipeline\"\nconfigFolderPath\u003dAIAA_ROOT+\"../Deepgrow2D3D_pipeline.json\"\n \n!AIAA load $modelName pipeline $configFolderPath \n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "\n## 3.6 Check for models loaded into AIAA\nLet us check the server and check that the model is uploaded. \nCell below would list models loaded by the AIAA server "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "!AIAA list "
    },
    {
      "cell_type": "markdown",
      "source": "## 3.7 (Optional for advanced users) Loading models using curl commands\nFor advanced users or programmers integrating with AIAA, \nThey could do the above task using curl commands as:  \n\n```\nhttp_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/admin/model/\"+modelName\nconf_str\u003d\"config\u003d@\"+downloadDir+modelName+\"/config/config_aiaa.json;type\u003dapplication/json\"\ndataArg\u003d\"data\u003d@\"+downloadDir+modelName+\"/models/model.ts\"\ncmd\u003d\u0027curl -X PUT \"\u0027+http_str +\u0027\" -F \"\u0027+conf_str +\u0027\" -F \"\u0027+dataArg +\u0027\"\u0027\n```\nCommand below would download from NGC and load the deep grow and spleen segmentation model to AIAA\n```\n# model name from NGC is clara_train_deepgrow_aiaa_inference_only\nhttp_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/admin/model/clara_deepgrow\"\n!curl -X PUT $http_str \\\n     -H \"accept: application/json\" \\\n     -H \"Content-Type: application/json\" \\\n     -d \u0027{\"path\":\"nvidia/med/clara_train_deepgrow_aiaa_inference_only\",\"version\":\"1\"}\u0027\n```\n```\nhttp_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/admin/model/clara_ct_seg_spleen\"\n!curl -X PUT $http_str \\\n     -H \"accept: application/json\" \\\n     -H \"Content-Type: application/json\" \\\n     -d \u0027{\"path\":\"nvidia/med/clara_ct_seg_spleen\",\"version\":\"1\"}\u0027\n```\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "# 4. AIAA Clients \n\nAIAA server can connect to any client that implements the APIs found [here](https://github.com/NVIDIA/ai-assisted-annotation-client\n). \nNVIDIA has already implemented these APIs for a number of open source viewers as:\n"
    },
    {
      "cell_type": "markdown",
      "source": "## 4.1. [3D Slicer](https://www.slicer.org/)\n\nIn order to use slicer you should: \n1. Install and setup slicer 3d following steps [here](https://github.com/NVIDIA/ai-assisted-annotation-client/tree/master/slicer-plugin)\n    1. Download and install recent 3D Slicer Preview Release (4.11.x) from [here](http://download.slicer.org/).\n    For Early access please use slicer 4.13 (unstable release) this is needed to enable 3d geepgrow models. \n    2. Start 3D Slicer and open the Extension manager\n    3. Install NvidiaAIAssistedAnnotation extension (in Segmentation category), wait for the installation to complete, and click Restart\n2. Install by searching for nvidia in the plugin manager\n3. Configure plugin. Add the AIAA server location and make sure the session is enabled\n   \u003cbr\u003e\u003cimg src\u003d\"screenShots/SlicerConfig.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\n4. You should load a volume and start trying the spleen and deep grow model as shown below\n     \n\u003cbr\u003e\u003cimg src\u003d\"screenShots/Slicer.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 4.2. [MITK](https://www.mitk.org/wiki/The_Medical_Imaging_Interaction_Toolkit_(MITK))\nMITK is another viewer that you can use with AIAA. \nYou can download and install it [here](http://mitk.org/wiki/Downloads). \nPlease make sure you install the release with nvidia AIAA.\u003cbr\u003e\n_Note_: Deep grow is not enabled yet in MITK \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 4.3. [OHIF](https://docs.ohif.org/)\nWe have integrated AIAA with OHIF as a plugin, This has also been adapted in to XNAT. \nPlugin code can be found as a [branch of OHIF github](https://github.com/SachidanandAlle/Viewers). \n\nFor more on how to use OHIF please see [OHIF Notebook](AIAAwOHIF.ipynb)",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 5. Delete Models from AIAA server  ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# if you need to change the model name \n#modelName\u003d\"Deepgrow3DV4EA\"\n!AIAA delete $modelName\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Or use the http API\n```\nhttp_str\u003d\u0027\"http://127.0.0.1:\u0027+AIAA_PORT+\u0027/admin/model/\u0027+modelName+\u0027\"\u0027\n!curl -X DELETE $http_str\n```\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 6. Stop AIAA server\nIn order to stop the AIAA server you can run cell below.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "!AIAA stop"
    },
    {
      "cell_type": "markdown",
      "source": "\nHowever, this will **not free up your gpu memory** \nsince we are using **triton which is running in another container.**\nIn order to release the gpu memory you would need to either stop the triton container, \nor delete the models from the triton model directory `/claraDevDay/AIAA/workspace/triton_models/`",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "#!mkdir $AIAA_ROOT/triton_models_full\n#!mv $AIAA_ROOT/triton_models_full_back/* $AIAA_ROOT/triton_models_full/ ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "\u003c!--- SPDX-License-Identifier: Apache-2.0 --\u003e\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}