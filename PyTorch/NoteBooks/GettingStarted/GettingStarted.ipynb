{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Getting started with Clara Train SDK V4.0 PyTorch using MONAI \n",
    "Clara Train SDK simply allows researcher to train AI models using configuration files. \n",
    "It is simple to use, modular and flexible. Allowing researchers to focus on innovation, \n",
    "while leaving acceleration and performance issue for NVIDIA's engineers. \n",
    "\n",
    "Clara Train SDK consists of different modules as shown below \n",
    "<br><img src=\"screenShots/TrainBlock.png\" alt=\"Drawing\" style=\"height: 600px;\"/><br>\n",
    "   \n",
    "By the end of this notebook you will:\n",
    "1. Understand components of [Medical Model ARchive (MMAR)](https://docs.nvidia.com/clara/clara-train-sdk/pt/mmar.html)\n",
    "2. Know how to configure train config json to train a CNN\n",
    "3. Train a CNN with single and multiple GPUs\n",
    "4. Fine tune a model\n",
    "5. Export a model \n",
    "6. Perform inference on testing dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Prerequisites\n",
    "- Nvidia GPU with 8Gb of memory   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Resources\n",
    "You could watch the free GTC 2021 talks covering Clara Train SDK\n",
    "- [Clara Train 4.0 - 101 Getting Started [SE2688]](https://www.nvidia.com/en-us/on-demand/session/gtcspring21-se2688/)\n",
    "- [Clara Train 4.0 - 201 Federated Learning [SE3208]](https://www.nvidia.com/en-us/on-demand/session/gtcspring21-se3208/)\n",
    "- [Take Medical AI from Concept to Production using Clara Imaging [S32482]](https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s32482/)\n",
    "- [Federated Learning for Medical AI [S32530]](https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s32530/) \n",
    "- [Get Started Now on Medical Imaging AI with Clara Train on Google Cloud Platform [S32518]](https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s32518/)\n",
    "- [Automate 3D Medical Imaging Segmentation with AutoML and Neural Architecture Search [S32083]](https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s32083/)\n",
    "- [A Platform for Rapid Development and Clinical Translation of ML Models for Applications in Radiology at UCSF [S31619]](https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s31619/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Background\n",
    "\n",
    "Clara Train is built using a component-based architecture with using components from [MONAI](https://monai.io/) :\n",
    "MONAI’s [training workflows](https://docs.monai.io/en/latest/highlights.html#workflows) \n",
    "are based off of [PyTorch Ignite’s engine](https://pytorch.org/ignite/engine.html). \n",
    "Below is a list of different components used:\n",
    "- Training Data Pipeline\n",
    "- Validation Data Pipeline\n",
    "- [Applications](https://docs.monai.io/en/latest/apps.html)\n",
    "- [Transforms](https://docs.monai.io/en/latest/transforms.html)\n",
    "- [Data](https://docs.monai.io/en/latest/data.html)\n",
    "- [Engines](https://docs.monai.io/en/latest/engines.html)\n",
    "- [Inference methods](https://docs.monai.io/en/latest/inferers.html)\n",
    "- [Event handlers](https://docs.monai.io/en/latest/handlers.html)\n",
    "- [Network architectures](https://docs.monai.io/en/latest/networks.html)\n",
    "- [Loss functions](https://docs.monai.io/en/latest/losses.html)\n",
    "- [Optimizers](https://docs.monai.io/en/latest/optimizers.html)\n",
    "- [Metrics](https://docs.monai.io/en/latest/metrics.html)\n",
    "- [Visualizations](https://docs.monai.io/en/latest/visualize.html)\n",
    "- [Utilities](https://docs.monai.io/en/latest/utils.html)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Lets get started\n",
    "Before we get started lets check that we have an NVIDIA GPU available in the docker by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# following command should show all gpus available \n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Next cell defines functions that we will use throughout the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MMAR_ROOT=\"/claraDevDay/GettingStarted/\"\n",
    "print (\"setting MMAR_ROOT=\",MMAR_ROOT)\n",
    "%ls $MMAR_ROOT\n",
    "\n",
    "!chmod 777 $MMAR_ROOT/commands/*\n",
    "def printFile(filePath,lnSt,lnEnd):\n",
    "    print (\"showing \",str(lnEnd-lnSt),\" lines from file \",filePath, \"starting at line\",str(lnSt))\n",
    "    !< $filePath head -n \"$lnEnd\" | tail -n +\"$lnSt\"\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Medical Model ARchive (MMAR)\n",
    "Clara Train SDK uses the [Medical Model ARchive (MMAR)](https://docs.nvidia.com/clara/clara-train-sdk/pt/mmar.html). \n",
    "The MMAR defines a standard structure for organizing all artifacts produced during the model development life cycle. \n",
    "Clara Train SDK simple basic idea is to train using config file\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "**We recommend opening [config_train_Unet.json](config/config_train_Unet.json) and configuring your screen as shown below**\n",
    "<br><img src=\"screenShots/MMAR.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "You can download sample models for different problems from [NGC](https://ngc.nvidia.com/catalog/models?orderBy=modifiedDESC&pageNumber=0&query=clara&quickFilter=&filters=) <br> \n",
    "All MMAR follow the structure provided in this Notebook. if you navigate to the parent folder structure it should contain the following subdirectories\n",
    "```\n",
    "./GettingStarted \n",
    "├── commands\n",
    "├── config\n",
    "├── docs\n",
    "├── eval\n",
    "├── models\n",
    "└── resources\n",
    "```\n",
    "\n",
    "* `commands` contains a number of ready-to-run scripts for:\n",
    "    - training\n",
    "    - training with multiple GPU\n",
    "    - fine tune\n",
    "    - fine tune with multiple GPU\n",
    "    - validation\n",
    "    - validation with multiple GPU\n",
    "    - inference (testing)\n",
    "    - exporting models in TensorRT Inference Server format\n",
    "* `config` contains configuration files (in JSON format) for eac training, \n",
    "validation, and deployment for [AI-assisted annotation](https://docs.nvidia.com/clara/clara-train-sdk/aiaa/index.html) \n",
    "(_Note:_ these configuration files are used in the scripts under the `commands` folder)\n",
    "* `docs` contains local documentation for the model, but for a more complete view it is recommended you visit the NGC model page\n",
    "* `eval` is used as the output directory for model evaluation (by default)\n",
    "* `models` is where the PyTorch checkpoint model is stored, and the corresponding graph definition files.\n",
    "* `resources` currently contains the logger configuration in `log.config` file\n",
    "\n",
    "Some of the most important files you will need to understand to configure and use Clara Train SDK are\n",
    "\n",
    "1. `environment.json` which has important common parameters to set the path for \n",
    "    * `DATA_ROOT` is the root folder where the data with which we would like to train, validate, or test resides in\n",
    "    * `DATASET_JSON` expects the path to a JSON-formatted file \n",
    "    * `MMAR_CKPT_DIR` the path to the where the PyTorch checkpoint files reside\n",
    "    * `MMAR_EVAL_OUTPUT_PATH` the path to output evaluation metrics for the neural network during training, validation, and inference\n",
    "    * `PROCESSING_TASK` the type of processing task the neural net is intended to perform (currently limited to `annotation`, `segmentation`, `classification`)\n",
    "    * `PRETRAIN_WEIGHTS_FILE` (_optional_) \tdetermines the location of the pre-trained weights file; if the file does not exist and is needed, \n",
    "    the training program will download it from predefined URL from the web\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "printFile(MMAR_ROOT+\"/config/environment.json\",0,30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Config.json Main Concepts \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "`config_train.json` contains all the parameters necessary to define the neural net, \n",
    "how is it trained (training hyper-parameters, loss, etc.), \n",
    "pre- and post-transformation functions necessary to modify and/or augment the data before input to the neural net, etc. \n",
    "The complete documentation on the training configuration is laid out \n",
    "[here](https://docs.nvidia.com/clara/clara-train-sdk/pt/appendix/configuration.html#training-configuration).\n",
    "Configuration file defines all training related configurations. \n",
    "This is were most the researcher would spent most of his time.\n",
    "\n",
    "Please see our documentation for detailed explanation of the [training configuration](https://docs.nvidia.com/clara/clara-train-sdk/pt/appendix/configuration.html#training-configuration)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 4. Training your first Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.1 Training script \n",
    "We have renamed `train.sh` to `train_W_Config` as we modified it to accept parameters with the config to use\n",
    "\n",
    "Let's take a look at `train_W_Config.sh` by executing the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "printFile(MMAR_ROOT+\"/commands/train_W_Config.sh\",0,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 4.2 Start training\n",
    "Now that we have our training configuration, to start training simply run `train.sh` as below. \n",
    "Please keep in mind that we have setup a dummy data with one file to train a dummy network fast (we only train for 2 epochs). \n",
    "Please see exercises on how to easily switch data and train a real segmentation network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! $MMAR_ROOT/commands/train_W_Config.sh config_train_Unet.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Now lets see the `models` directory, which would includes out models and the tensorboard files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! ls -la $MMAR_ROOT/models/config_train_Unet\n",
    "!echo ---------------------------------------\n",
    "!echo Display content of train_stats.json\n",
    "! cat $MMAR_ROOT/models/config_train_Unet/train_stats.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "# 5. Export Model\n",
    "\n",
    "To export the model we simply run `export.sh` which will: \n",
    "- Create ts file\n",
    "This optimized model will be used by TRITON server in AIAA and Clara Deploy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! $MMAR_ROOT/commands/export.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "\n",
    "lets check out what was created in the folder. \n",
    "after running cell below you should see `model.ts`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!ls -la $MMAR_ROOT/models/config_train_Unet/*.ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "# 6. Validation \n",
    "Now that we have trained our model we would like to run evaluation to get some statistics and also do inference to see the resulted output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 6.1 Validate with single GPU \n",
    "To run evaluation on your validation dataset you should run `validate.sh`. \n",
    "This will run evaluation on the validation dataset and place it in the `MMAR_EVAL_OUTPUT_PATH` as configured in the [environment.json](config/environment.json) \n",
    "file (default is eval folder). \n",
    "This evaluation would give min, max, mean of the metric as specified in the config_validation file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! $MMAR_ROOT/commands/validate.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "You could also run `validate_ckpt.sh` which loads the model from the checkpoint instead of the ts file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! $MMAR_ROOT/commands/validate_ckpt.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 6.2 Validate with multiple GPUs \n",
    "You can also leverage multi-GPUs for validation using `validate_multi_gpu.sh` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!$MMAR_ROOT/commands/validate_multi_gpu.sh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Similarly you could also run `validate_multi_gpu_ckpt.sh` which loads the model from the checkpoint instead of the ts file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! $MMAR_ROOT/commands/validate_multi_gpu_ckpt.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 6.3 Check Validation results \n",
    "Now lets see results in the folder by running cells below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!ls -la $MMAR_ROOT/eval\n",
    "for fName in [\"metrics.csv\",\"val_mean_dice_raw.csv\",\"val_mean_dice_summary.csv\"]:\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"Display content of \",fName)\n",
    "    ! cat $MMAR_ROOT/eval/$fName\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 7. Inference  \n",
    "\n",
    "To run inference on validation dataset or test dataset you should run `infer.sh`. \n",
    "This will run prediction on the validation dataset and place it in the `MMAR_EVAL_OUTPUT_PATH` as configured in the \n",
    "[environment.json](config/environment.json) file (default is eval folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! $MMAR_ROOT/commands/infer.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Now lets see results in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! ls -la $MMAR_ROOT/eval/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! ls -la $MMAR_ROOT/eval/spleen_8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 8.Multi-GPU Training\n",
    "Clara train aims to simplify scaling and utilizing all available GPUs. \n",
    "Using the same config we already used for train we can simply invoke `train_multi_gpu.sh` to train on multiple gpus. \n",
    "Main difference between the `train.sh` and `train_multi_gpu.sh` is changing some parameters\n",
    "\n",
    "train.sh | train_multi_gpu.sh  \n",
    " --- | --- \n",
    "python3 -u -m medl.apps.train \\\\<br>-m MMAR_ROOT \\\\<br>-c CONFIG_FILE \\\\<br>-e ENVIRONMENT_FILE \\\\<br>--write_train_stats \\\\<br>--set \\\\<br> print_conf=True | python -m torch.distributed.launch\\\\<br> --nproc_per_node=2 --nnodes=1 --node_rank=0 \\\\<br> --master_addr=\"localhost\" --master_port=1234 \\\\<br>-m medl.apps.train \\\\<br>-m MMAR_ROOT \\\\<br>-c CONFIG_FILE \\\\<br>-e ENVIRONMENT_FILE \\\\<br> --write_train_stats \\\\<br> --set \\\\<br> print_conf=True \\\\<br> multi_gpu=True \\\\<br> learning_rate= 2e-4\n",
    " \n",
    "Lets examine `train_multi_gpu.sh` script by running cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "printFile(MMAR_ROOT+\"/commands/train_multi_gpu.sh\",0,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Lets give it a try and run cell below to train on 2 GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! $MMAR_ROOT/commands/train_multi_gpu.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "# 9. Training Vs FineTune\n",
    "`train.sh` and `finetune.sh` are identical and use the same config file. \n",
    "The only difference is that `finetune.sh` enables the load of check point using the `disabled` as shown below \n",
    "\n",
    "except they train using different configurations files. \n",
    "\n",
    "_Note_: The only difference between the two configs `config_train_Unet.json` and `config_finetune.json` \n",
    "is that `config_finetune.json` specifies a `ckpt` file in section below \n",
    "while `config_train_Unet.json` does not since it is training from scratch.\n",
    "```\n",
    "      {\n",
    "        \"name\": \"CheckpointLoader\",\n",
    "        \"args\": {\n",
    "          \"disabled\": \"{dont_load_ckpt_model}\",\n",
    "          \"load_path\": \"{MMAR_CKPT}\",\n",
    "          \"load_dict\": [\"model\"]\n",
    "        }\n",
    "      },\n",
    "```\n",
    "\n",
    "# Next:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### 1. Load model into AIAA\n",
    "We will show here how you can quickly load up the model we trained above into AIAA. \n",
    "First, you should run [AIAA Notebook](../AIAA/AIAA.ipynb) to start the server.\n",
    "Section 3.1 in the AIAA notebook shows how to load trained model into AIAA server. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### 2. Bring your own Components\n",
    "In order to fully take advantage of clara train SDK you should write your own components. \n",
    "Please go to [BYOC notebook](BYOC.ipynb) for examples  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Exercise:\n",
    "Now that you are familiar with clara train, you can try to: \n",
    "1. Explore different options of clara train by changing / creating a new config file and running training: \n",
    "    1. Model architecture: Ahnet, Unet, Segresnet \n",
    "    2. Losses\n",
    "    3. Transformation \n",
    "\n",
    "Hint: you for training segresnet you can use the configuration `config_train_segresnet.json` that only changed the network section.\n",
    "you can train by running cell below     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!$MMAR_ROOT/commands/train_W_Config.sh config_train_segresnet.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. Train on real spleen data for this you should:\n",
    "    1. Download spleen dataset by running the [download](../Data/DownloadDecathlonDataSet.ipynb) Notebook\n",
    "    2. Switch the dataset file in the [environment.json](config/environment.json)\n",
    "    3. rerun the `train.sh`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "3. Experiment with multi-GPU training by changing number of gpus to train on from 2 to 3 or 4. \n",
    "You should edit [train_multi_gpu.sh](commands/train_multi_gpu.sh) then rerun the script \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": "<!--- SPDX-License-Identifier: Apache-2.0 -->\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
