{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Bring your own components (BYOC)\n",
    "\n",
    "Starting in V4 Clara train is based of MONAI \n",
    "from their website \n",
    "\"The MONAI framework is the open-source foundation being created by Project MONAI. \n",
    "MONAI is a freely available, community-supported, \n",
    "PyTorch-based framework for deep learning in healthcare imaging. \n",
    "It provides domain-optimized foundational capabilities for developing healthcare imaging training workflows in a native PyTorch paradigm.\"\n",
    "<br><img src=\"screenShots/MONAI.png\" alt=\"Drawing\" style=\"height: 200px;width: 400px\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Clara Train SDK is modular and flexible enough to allow researchers to bring their own components including:\n",
    "1. [Transformations](https://docs.monai.io/en/latest/transforms.html#) \n",
    "2. [Loss functions](https://docs.monai.io/en/latest/losses.html)\n",
    "3. [Model Architecture](https://docs.monai.io/en/latest/networks.html)\n",
    "4. [Loaders](https://docs.nvidia.com/clara/tlt-mi/clara-train-sdk-v3.0/nvmidl/byom.html#bring-your-own-data-loader)\n",
    "5. [Metrics](https://docs.monai.io/en/latest/metrics.html)\n",
    "\n",
    "By the end of this notebook you should be able to bring your own components mentioned above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Prerequisites\n",
    "- Familiar with Clara train main concepts. See [Getting Started Notebook](../GettingStarted/GettingStarted.ipynb)\n",
    "- Nvidia GPU with 8Gb of memory   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Dataset \n",
    "This notebook uses a sample dataset (ie. a single image of a spleen dataset) provided in the package to train a small neural network for a few epochs. \n",
    "This single file is duplicated 32 times for the training set and 9 times for the validation set to mimic the full spleen dataset. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Lets get started\n",
    "It is helpful to check that we have an NVIDIA GPU available in the docker by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# following command should show all gpus available \n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 1.1 General Concept\n",
    "You can easily BYOC into Clara Train SDK by writing your python code then point to it in the `config.json` using `path` instead of the `name` tag. \n",
    "Throughout this notebook we have placed all of our examples from our documentations into the [BYOC](BYOC) folder. \n",
    "\n",
    "Normal | BYOC  \n",
    " --- | ---  \n",
    "{<br>\"name\": \"CropFixedSizeRandomCenter\", <br> \"args\": {\"fields\": \"image\"}<br> } | { <br> \"path\": \"myTransformation.MyAddRandomConstant\", <br> \"args\": {\"fields\": \"image\"}<br> } \n",
    "\n",
    " \n",
    "We modified the [set_env.sh](commands/set_env.sh) to include the path. \n",
    "Let us run the cells below that define some helper functions we will be using and see where we added the BYOC to the pythonpath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MMAR_ROOT=\"/claraDevDay/GettingStarted/\"\n",
    "print (\"setting MMAR_ROOT=\",MMAR_ROOT)\n",
    "%ls $MMAR_ROOT\n",
    "\n",
    "!chmod 777 $MMAR_ROOT/commands/*\n",
    "def printFile(filePath,lnSt,lnEnd):\n",
    "    print (\"showing \",str(lnEnd-lnSt),\" lines from file \",filePath, \"starting at line\",str(lnSt))\n",
    "    !< $filePath head -n \"$lnEnd\" | tail -n +\"$lnSt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 1.2 Add BYOC folder to PYTHONPATH \n",
    "It is important to add the folder containing your code to the PYTHONPATH variable.\n",
    "The easiest way to do this is to add it to the `set_env.sh` file since it is called from all the train commands.\n",
    "Let's take a look at this `set_env.sh` file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "printFile(MMAR_ROOT+\"/commands/set_env.sh\",0,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 2.1 BYO Transformation: Adding random noise to image pixels\n",
    "Now lets write a full transformation `MyRandAdditiveNoised` from scratch. For this you need to:\n",
    "1. Implement `Randomizable` and `MapTransform`\n",
    "2. Define `__call__` function. \n",
    "Also define `set_random_state` and `randomize` functions for Randomizable\n",
    "\n",
    "see how we did this in by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "printFile(MMAR_ROOT+\"/custom/myTransformation.py\",16,30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Now to run this we need to modify the train config by setting the `path` \n",
    "to our newly created transformation `myTransformation.MyRandAdditiveNoised`. \n",
    "We also would like to debug the output so we will add the `SaveImageD` Transform. \n",
    "This transform would pause the training and save batches to `output_dir` for us to check.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "configFile=MMAR_ROOT+\"/config/trn_BYOC_transform.json\"\n",
    "printFile(configFile,0,50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 2.2 Run and see Debugging Data\n",
    "So let us now run training and see the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! $MMAR_ROOT/commands/train_W_Config.sh trn_BYOC_transform.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "Now let us see the sample images in the debug folder  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! ls -la /claraDevDay/Data/_tmpDebugPatches/\n",
    "! ls -la /claraDevDay/Data/_tmpDebugPatches/spleen_8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "## 3. BYO Network Architecture and Loss\n",
    "Clara Train SDK also allows you to write your own network architecture as well as your loss function. \n",
    "In this example we have a shallow Unet architecture defined in [myNetworkArch.py](BYOC/myNetworkArch.py) \n",
    "as well as our own dice loss defined in [myLoss.py](BYOC/myLoss.py). \n",
    "\n",
    "Normal | BYOC  \n",
    " --- | --- \n",
    "\"loss\": {<br> \"name\": \"DiceLoss\",<br> \"args\":{ ...      } <br>}, | \"loss\": {<br> **\"path\"**: \"myLoss.MyDiceLoss\",<br>  \"args\": {... }<br>} |\n",
    "\"model\": {<br> \"name\": \"UNet\",<br>\"args\": { ... }<br>}, | \"model\": {<br>**\"path\"**: \"myNetworkArch.MyBasicUNet\",<br>\"args\": { ... }<br>},\n",
    " \n",
    "\n",
    "Let us see how it is defined   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "printFile(MMAR_ROOT+\"/custom/myNetworkArch.py\",0,30)\n",
    "printFile(MMAR_ROOT+\"/custom/myLoss.py\",0,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Let us Examine the config file [trn_BYOC_Arch_loss.json](config/trn_BYOC_Arch_loss.json) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "configFile=MMAR_ROOT+\"/config/trn_BYOC_Arch_loss.json\"\n",
    "printFile(configFile,11,18)\n",
    "printFile(configFile,32,43)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Now let us train our network  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "! $MMAR_ROOT/commands/train_W_Config.sh trn_BYOC_Arch_loss.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 4. Exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### 4.1. BYO Data Loader\n",
    "For this example we will see how to use a custom loader specifically to load a numpy file. \n",
    "To do this, we first load our nii.gz file and save it a np.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "dataRoot=\"/claraDevDay/Data/sampleData/\"\n",
    "for imgLb in [\"imagesTr\",\"labelsTr\"]:\n",
    "    filename= dataRoot+imgLb+\"/spleen_8.nii.gz\"\n",
    "    img = nib.load(filename)\n",
    "    data = img.get_fdata()\n",
    "    np.save(filename[:-7]+\".npy\",data)\n",
    "!ls -ls $dataRoot/imagesTr\n",
    "!ls -ls $dataRoot/labelsTr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now you should:\n",
    "1. Modify the environment file to point to [datasetNp.json](../Data/sampleData/datasetNp.json)\n",
    "2. write a numpy dataloader similar to the one in monai [NumpyReader](https://docs.monai.io/en/latest/_modules/monai/data/image_reader.html#NumpyReader)\n",
    "3. Change dataloader transformation to point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### 4.2. Modify custom loss\n",
    "\n",
    "Modify the custom loss file to be a weighted dice loss per label.\n",
    "\n",
    "Some Tips:\n",
    "\n",
    "1. You can add code below [myLoss.py](custom/myLoss.py) in the init function\n",
    "```\n",
    "    # uncomment lines below to enable label weights\n",
    "     self.label_weights=label_weights\n",
    "     if self.label_weights is not None:\n",
    "         self.label_weights=[x / sum(self.label_weights) for x in self.label_weights]\n",
    "         print (\"====== AEH applying label weights {} refactored as {}\".format(label_weights,self.label_weights))\n",
    "```\n",
    "2. Similarly uncomment the lines in the `forward` function to multiply the weights given with the loss  \n",
    "``` \n",
    " if self.label_weights is not None:  # add wights to labels\n",
    "     bs=intersection.shape[0]\n",
    "     w = torch.tensor(self.label_weights, dtype=torch.float32,device=torch.device('cuda:0'))\n",
    "     w= w.repeat(bs, 1) ## change size to [BS, Num of classes ]\n",
    "     intersection = w* intersection\n",
    "```\n",
    "3. You need to pass the weights by adding `label_weights` in the args of your loss in the training config\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": "<!--- SPDX-License-Identifier: Apache-2.0 -->\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
