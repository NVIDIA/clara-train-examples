{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "# Bring your own components (BYOC)\n\nStarting in V4 Clara train is based of MONAI \nfrom their website \n\"The MONAI framework is the open-source foundation being created by Project MONAI. \nMONAI is a freely available, community-supported, \nPyTorch-based framework for deep learning in healthcare imaging. \nIt provides domain-optimized foundational capabilities for developing healthcare imaging training workflows in a native PyTorch paradigm.\"\n\u003cbr\u003e\u003cimg src\u003d\"screenShots/MONAI.png\" alt\u003d\"Drawing\" style\u003d\"height: 200px;width: 400px\"/\u003e\u003cbr\u003e\n"
    },
    {
      "cell_type": "markdown",
      "source": "Clara Train SDK is modular and flexible enough to allow researchers to bring their own components including:\n1. [Transformations](https://docs.monai.io/en/latest/transforms.html#) \n2. [Loss functions](https://docs.monai.io/en/latest/losses.html)\n3. [Model Architecture](https://docs.monai.io/en/latest/networks.html)\n4. [Loaders](https://docs.nvidia.com/clara/tlt-mi/clara-train-sdk-v3.0/nvmidl/byom.html#bring-your-own-data-loader)\n5. [Metrics](https://docs.monai.io/en/latest/metrics.html)\n\nBy the end of this notebook you should be able to bring your own components mentioned above.\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "## Prerequisites\n- Familiar with Clara train main concepts. See [Getting Started Notebook](../GettingStarted/GettingStarted.ipynb)\n- Nvidia GPU with 8Gb of memory   \n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "## Dataset \nThis notebook uses a sample dataset (ie. a single image of a spleen dataset) provided in the package to train a small neural network for a few epochs. \nThis single file is duplicated 32 times for the training set and 9 times for the validation set to mimic the full spleen dataset. \n    "
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "# Lets get started\n",
        "It is helpful to check that we have an NVIDIA GPU available in the docker by running the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# following command should show all gpus available \n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "## 1.1 General Concept\nYou can easily BYOC into Clara Train SDK by writing your python code then point to it in the `config.json` using `path` instead of the `name` tag. \nThroughout this notebook we have placed all of our examples from our documentations into the [BYOC](BYOC) folder. \n\nNormal | BYOC  \n --- | ---  \n{\u003cbr\u003e\"name\": \"CropFixedSizeRandomCenter\", \u003cbr\u003e \"args\": {\"fields\": \"image\"}\u003cbr\u003e } | { \u003cbr\u003e \"path\": \"myTransformation.MyAddRandomConstant\", \u003cbr\u003e \"args\": {\"fields\": \"image\"}\u003cbr\u003e } \n\n \nWe modified the [set_env.sh](commands/set_env.sh) to include the path. \nLet us run the cells below that define some helper functions we will be using and see where we added the BYOC to the pythonpath\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "MMAR_ROOT\u003d\"/claraDevDay/GettingStarted/\"\nprint (\"setting MMAR_ROOT\u003d\",MMAR_ROOT)\n%ls $MMAR_ROOT\n\n!chmod 777 $MMAR_ROOT/commands/*\ndef printFile(filePath,lnSt,lnEnd):\n    print (\"showing \",str(lnEnd-lnSt),\" lines from file \",filePath, \"starting at line\",str(lnSt))\n    !\u003c $filePath head -n \"$lnEnd\" | tail -n +\"$lnSt\""
    },
    {
      "cell_type": "markdown",
      "source": "## 1.2 Add BYOC folder to PYTHONPATH \nIt is important to add the folder containing your code to the PYTHONPATH variable.\nThe easiest way to do this is to add it to the `set_env.sh` file since it is called from all the train commands.\nLet\u0027s take a look at this `set_env.sh` file ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(MMAR_ROOT+\"/commands/set_env.sh\",0,20)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 2.1 BYO Transformation: Adding random noise to image pixels\nNow lets write a full transformation `MyRandAdditiveNoised` from scratch. For this you need to:\n1. Implement `Randomizable` and `MapTransform`\n2. Define `__call__` function. \nAlso define `set_random_state` and `randomize` functions for Randomizable\n\nsee how we did this in by running the cell below",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "printFile(MMAR_ROOT+\"/config/myTransformation.py\",16,30)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "Now to run this we need to modify the train config by setting the `path` \nto our newly created transformation `myTransformation.MyRandAdditiveNoised`. \nWe also would like to debug the output so we will add the `SaveImageD` Transform. \nThis transform would pause the training and save batches to `output_dir` for us to check.  "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "configFile\u003dMMAR_ROOT+\"/custom/trn_BYOC_transform.json\"\nprintFile(configFile,0,50)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "## 2.2 Run and see Debugging Data\nSo let us now run training and see the results "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "! $MMAR_ROOT/commands/train_W_Config.sh trn_BYOC_transform.json"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "\n",
        "Now let us see the sample images in the debug folder  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "! ls -la /claraDevDay/Data/_tmpDebugPatches/\n! ls -la /claraDevDay/Data/_tmpDebugPatches/spleen_8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "\n## 3. BYO Network Architecture and Loss\nClara Train SDK also allows you to write your own network architecture as well as your loss function. \nIn this example we have a shallow Unet architecture defined in [myNetworkArch.py](BYOC/myNetworkArch.py) \nas well as our own dice loss defined in [myLoss.py](BYOC/myLoss.py). \n\nNormal | BYOC  \n --- | --- \n\"loss\": {\u003cbr\u003e \"name\": \"DiceLoss\",\u003cbr\u003e \"args\":{ ...      } \u003cbr\u003e}, | \"loss\": {\u003cbr\u003e **\"path\"**: \"myLoss.MyDiceLoss\",\u003cbr\u003e  \"args\": {... }\u003cbr\u003e} |\n\"model\": {\u003cbr\u003e \"name\": \"UNet\",\u003cbr\u003e\"args\": { ... }\u003cbr\u003e}, | \"model\": {\u003cbr\u003e**\"path\"**: \"myNetworkArch.MyBasicUNet\",\u003cbr\u003e\"args\": { ... }\u003cbr\u003e},\n \n\nLet us see how it is defined   "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "printFile(MMAR_ROOT+\"/custom/myNetworkArch.py\",0,30)\nprintFile(MMAR_ROOT+\"/custom/myLoss.py\",0,30)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "Let us Examine the config file [trn_BYOC_Arch_loss.json](config/trn_BYOC_Arch_loss.json) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "configFile\u003dMMAR_ROOT+\"/config/trn_BYOC_Arch_loss.json\"\nprintFile(configFile,11,18)\nprintFile(configFile,32,43)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "Now let us train our network  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "\n! $MMAR_ROOT/commands/train_W_Config.sh trn_BYOC_Arch_loss.json\n"
    },
    {
      "cell_type": "markdown",
      "source": "# 4. Exercise ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 4.1. BYO Data Loader\nFor this example we will see how to use a custom loader specifically to load a numpy file. \nTo do this, we first load our nii.gz file and save it a np.  ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "import nibabel as nib\nimport numpy as np\ndataRoot\u003d\"/claraDevDay/Data/sampleData/\"\nfor imgLb in [\"imagesTr\",\"labelsTr\"]:\n    filename\u003d dataRoot+imgLb+\"/spleen_8.nii.gz\"\n    img \u003d nib.load(filename)\n    data \u003d img.get_fdata()\n    np.save(filename[:-7]+\".npy\",data)\n!ls -ls $dataRoot/imagesTr\n!ls -ls $dataRoot/labelsTr"
    },
    {
      "cell_type": "markdown",
      "source": "Now you should:\n1. Modify the environment file to point to [datasetNp.json](../Data/sampleData/datasetNp.json)\n2. write a numpy dataloader similar to the one in monai [NumpyReader](https://docs.monai.io/en/latest/_modules/monai/data/image_reader.html#NumpyReader)\n3. Change dataloader transformation to point.",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 4.2. Modify custom loss\n\nModify the custom loss file to be a weighted dice loss per label.\n\nSome Tips:\n\n1. You can add code below [myLoss.py](custom/myLoss.py) in the init function\n```\n    # uncomment lines below to enable label weights\n     self.label_weights\u003dlabel_weights\n     if self.label_weights is not None:\n         self.label_weights\u003d[x / sum(self.label_weights) for x in self.label_weights]\n         print (\"\u003d\u003d\u003d\u003d\u003d\u003d AEH applying label weights {} refactored as {}\".format(label_weights,self.label_weights))\n```\n2. Similarly uncomment the lines in the `forward` function to multiply the weights given with the loss  \n``` \n if self.label_weights is not None:  # add wights to labels\n     bs\u003dintersection.shape[0]\n     w \u003d torch.tensor(self.label_weights, dtype\u003dtorch.float32,device\u003dtorch.device(\u0027cuda:0\u0027))\n     w\u003d w.repeat(bs, 1) ## change size to [BS, Num of classes ]\n     intersection \u003d w* intersection\n```\n3. You need to pass the weights by adding `label_weights` in the args of your loss in the training config\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "\u003c!--- SPDX-License-Identifier: Apache-2.0 --\u003e\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}