{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# AI Assisted Annotation \n",
    "\n",
    "Manual annotation is slow, tediousÂ and costly. Faster labeling of 3D volumes using AI annotation models accelerates this process. Clara Train offers an AIAA API that easily integrates into common medical imaging viewers\n",
    "<br><img src=\"screenShots/AIAASpeedup.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>\n",
    "\n",
    "AIAA is based on a server client model as shown below \n",
    "<br><img src=\"screenShots/AIAAClientServer.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "By the end of this notebook you will be able to:\n",
    "- Start AIAA server \n",
    "- Load a deep grow model\n",
    "- Annotate using deep grow \n",
    "- Load your model and use it for annotations  \n",
    "- Stop AIAA server\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Prerequisites\n",
    "- Nvidia GPU with 8Gb of memory   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### Resources\n",
    "It might be helpful to watch the GTC Digital 2021 talk on Clara Train SDK\n",
    "- [Clara Train 4.0 - 101 Getting Started [SE2688]](https://www.nvidia.com/en-us/on-demand/session/gtcspring21-se2688/) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Lets get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "To interact with AIAA from the command line you should use the AIAA as `AIAA -h`. \n",
    "This would show you all commands as shown below\n",
    "```\n",
    "Usage: AIAA [-h] {start,stop,status,list,load,delete} ...\n",
    "\n",
    "commands:\n",
    "  start   Start AIAA Server\n",
    "          AIAA start -h\n",
    "  stop    Stop AIAA Server\n",
    "  status  Check if AIAA Server is running\n",
    "  list    List all models loaded in AIAA\n",
    "  logs    Fetch AIAA Logs if server is running <lines>\n",
    "  load    Load a model to AIAA using one of the sources {ngc|mmar|zip|config}\n",
    "          sources:\n",
    "            ngc      Load model from NGC\n",
    "                     AIAA load <model> ngc <path> <version>\n",
    "            mmar     Load model from MMAR Folder\n",
    "                     AIAA load <model> mmar <path>\n",
    "            zip      Load model from ZIP Archive\n",
    "                     AIAA load <model> zip <path>\n",
    "            config   Load model using AIAA Config and Model saved file\n",
    "                     AIAA load <model> config <aiaa_config> <saved_model>\n",
    "            pipeline Load pipeline (as vitual model) using AIAA Config\n",
    "                     AIAA load <model> config <aiaa_config>\n",
    "  delete  Delete a model from AIAA\n",
    "          AIAA delete <model>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Before we get started let us check that we have an NVIDIA GPU available in the docker by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# following command should show all gpus available \n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "# 1. Start AIAA server\n",
    "First lets set up AIAA path and change some permissions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "AIAA_ROOT=\"/claraDevDay/AIAA/workspace/\"\n",
    "AIAA_PORT=\"5000\"\n",
    "!mkdir -p $AIAA_ROOT\n",
    "!chmod 777 $AIAA_ROOT\n",
    "print (\"AIAA_ROOT is set to \",AIAA_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "##  1.1 AIAA Server with AIAA backend \n",
    "For simple POC or getting started with AIAA you could use the AIAA backend which is simpler to setup.\n",
    "For performance, we recommend you use triton as in the section below\n",
    "\n",
    "Unfortunately, Jupyter cells can't run a command as background.\n",
    "So you would need to run one of the commands below from a terminal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# start AIAA with AIAA backend  \n",
    "#AIAA start -w /claraDevDay/AIAA/workspace/ --engine AIAA &\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "##  1.2 AIAA Server with Triton BackEnd \n",
    "Starting V4.0 Triton server was moved out of the clara train container. \n",
    "In order to use Triton as the AIAA backend, you should use `startClaraTrainNoteBooks.sh`. \n",
    "The script uses docker-compose to start both the clara train container and triton container, \n",
    "while connected them through the docker internal network. \n",
    "You could also start AIAA server without triton using the AIAA backend option.\n",
    "\n",
    "Unfortunately, Jupyter cells can't run a command as background.\n",
    "So you would need to run one of the commands below from a terminal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# start AIAA with triton \n",
    "#AIAA start -b -w $AIAA_ROOT --engine TRITON --triton_ip tritonserver &\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 2 Check on AIAA Server "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.1 using CLI\n",
    "You should check on the AIAA status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!AIAA status   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "You can also get the last 15 lines of the logs use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!AIAA logs 15 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "You can then easily filter on errors as  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!AIAA logs |grep errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "To list models you can run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!AIAA list | grep name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!AIAA list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "### 2.2 Using Browser\n",
    "You can also check on the AIAA server using your browser by checking:\n",
    "- Main url `http://localhost:5000/` <br>\n",
    "- APIS to list, upload, delete models `http://localhost:5000/docs/`\n",
    "- Check logs `http://localhost:5000/logs`\n",
    "- List available models `http://localhost:5000/v1/models/` \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### 2.3 (For advanced users) Using curl commands\n",
    "You can also use curl command to:\n",
    "- check on gpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "http_str=\"http://127.0.0.1:\"+AIAA_PORT+\"/monailabel/logs/gpu\"\n",
    "!curl -X GET $http_str -H \"accept: application/json\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "- List models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "http_str=\"http://127.0.0.1:\"+AIAA_PORT+\"/v1/models\"\n",
    "!curl -X GET $http_str -H \"accept: application/json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "#  3. Load models in AIAA Server. \n",
    "For this notebook we can download models from [NGC](). Models on NGC are either:\n",
    "- Annotation Models <br>\n",
    "[Deep Extreme Cut: From Extreme Points to Object Segmentation](https://arxiv.org/abs/1711.09081)\n",
    "<br><img src=\"screenShots/AIAAAnnotation.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>\n",
    "\n",
    "- Segmentation Models\n",
    "- DeepGrow MMAR \n",
    "This is an interactive model to get you started with annotation. \n",
    "CNN takes in single channel (image) + use single click for foreground or background location then produces the segmentation. \n",
    "It is based on [Interactive segmentation of medical images through\n",
    "fully convolution neural networks](https://arxiv.org/pdf/1903.08205.pdf)\n",
    "<br><img src=\"screenShots/AIAADeepGrow.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 3.0 Loading options\n",
    "In order to load a model to AIAA we will use the AIAA cli as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! AIAA load -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "This will show you options which allows to load from ngc or a local MMAR or a local zip file, etc \n",
    "```\n",
    "root@claratrain:/claraDevDay/AIAA# AIAA load -h\n",
    "Loading Model: -h\n",
    "Usage: AIAA load <model> {ngc|mmar|zip|config|pipeline} ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 3.1 Load model trained from Getting started notebook\n",
    "In order to load model trained in the getting started notebook you can run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modelName=\"Test\"\n",
    "modelFolderPath=\"/claraDevDay/GettingStarted/models/config_train_Unet/model.ts\"\n",
    "configFolderPath=\"/claraDevDay/GettingStarted/config/config_aiaa.json\"\n",
    "!AIAA load $modelName config $configFolderPath $modelFolderPath \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 3.2 Using NGC CLI to download model from NGC\n",
    "You can see a [list of available pre-trained models](https://ngc.nvidia.com/containers/nvidia:clara-train-sdk) on NGC. \n",
    "You can also use `ngc registry model list nvidia/med/clara_*` to get a list of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!ngc registry model list nvidia/med/clara_pt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# you can then filter on the model you want so it is easier to grab the repository path \n",
    "!ngc registry model list nvidia/med/*spleen_ct_segment*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "The cell below will list the deepgrow models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# you can then filter on the model you want so it is easier to grab the repository path \n",
    "!ngc registry model list nvidia/med/*clara_pt_deepgrow*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "The cell below will download the the deep grow model from NGC and load it to AIAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!AIAA load deepgrow3d ngc \"nvidia/med/clara_pt_deepgrow_3d_annotation\" 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "The following cell will download the spleen model and load it into the AIAA server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !AIAA load spleen_seg ngc \"nvidia/med/clara_pt_spleen_ct_segmentation\" 1\n",
    "!curl -X PUT \"http://127.0.0.1:5000/admin/model/clara_pt_spleen_ct_segmentation\" -F 'ngc={\"path\":\"nvidia/med/clara_pt_spleen_ct_segmentation\",\"version\":\"1\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !AIAA load liver_seg ngc \"nvidia/med/clara_pt_liver_and_tumor_ct_segmentation\" 1\n",
    "!curl -X PUT \"http://127.0.0.1:5000/admin/model/clara_pt_liver_and_tumor_ct_segmentation\" -F 'ngc={\"path\":\"nvidia/med/clara_pt_liver_and_tumor_ct_segmentation\",\"version\":\"1\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 3.3 Manually Download model from NGC \n",
    "You can also download the publically available models directly through the NGC UI.  In this example, we're using DeepGrow 3D which you can find here: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/med/models/clara_pt_deepgrow_3d_annotation. Click on the ... button as shown below\n",
    "<br><img src=\"screenShots/DownloadFromNGC.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "**You should download zip file to /claraDevDay/AIAA/DownloadsFromNGC/**\n",
    "\n",
    "For example if you downloaded the covid segmentation model and named the file `CovidsegModel.zip`, \n",
    "then you can run cell below to load up the zipped file to AIAA server \n",
    "\n",
    "**Please make sure the zip file directly contains the mmar folder structure \n",
    "Error will occur if the zipped file contains a folder before the mmar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "downloadedFile=\"CovidsegModel.zip\"\n",
    "\n",
    "downloadDir=AIAA_ROOT+\"../DownloadsFromNGC/\"\n",
    "modelName=downloadedFile[:-4]\n",
    "zipmodelPath=downloadDir+downloadedFile\n",
    "!AIAA load $modelName zip $zipmodelPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 3.3.1 (optional) In case of error with zip file\n",
    "In case the zip files container an extra directory, you can unzip using cell below\n",
    "Zip file should have the MMAR structure. \n",
    "Cell below would unzip the MMAR then upload it to AIAA server \n",
    "```\n",
    "downloadedFile=\"deepgrow_3d.zip\"\n",
    "\n",
    "downloadDir=AIAA_ROOT+\"../DownloadsFromNGC/\"\n",
    "modelName=downloadedFile[:-4]\n",
    "modelFolderPath=downloadDir+modelName\n",
    "\n",
    "%cd $downloadDir\n",
    "!unzip $downloadedFile -d $modelName\n",
    "# then you should load the mmar to AIAA \n",
    "\n",
    "!AIAA load $modelName mmar $modelFolderPath\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 3.4 load a pipeline created from multiple models into AIAA\n",
    "AIAA now supports the concept of a pipelines which triggers multiple models one at a time.\n",
    "cell below creates a pipeline out of 3D deepgrow which gets new seed points for multiple runs of deepgrow 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modelName=\"GA_Deepgrow_Pipeline\"\n",
    "configFolderPath=AIAA_ROOT+\"../Deepgrow2D3D_pipeline.json\"\n",
    " \n",
    "!AIAA load $modelName pipeline $configFolderPath \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "## 3.5 Check for models loaded into AIAA\n",
    "Let us check the server and check that the model is uploaded. \n",
    "Cell below would list models loaded by the AIAA server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!AIAA list |grep name  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 3.6 (Optional for advanced users) Loading models using curl commands\n",
    "For advanced users or programmers integrating with AIAA, \n",
    "They could do the above task using curl commands as:  \n",
    "\n",
    "```\n",
    "http_str=\"http://127.0.0.1:\"+AIAA_PORT+\"/admin/model/\"+modelName\n",
    "conf_str=\"config=@\"+downloadDir+modelName+\"/config/config_aiaa.json;type=application/json\"\n",
    "dataArg=\"data=@\"+downloadDir+modelName+\"/models/model.ts\"\n",
    "cmd='curl -X PUT \"'+http_str +'\" -F \"'+conf_str +'\" -F \"'+dataArg +'\"'\n",
    "```\n",
    "Command below would download from NGC and load the deep grow and spleen segmentation model to AIAA\n",
    "```\n",
    "# model name from NGC is clara_train_deepgrow_aiaa_inference_only\n",
    "http_str=\"http://127.0.0.1:\"+AIAA_PORT+\"/admin/model/clara_deepgrow\"\n",
    "!curl -X PUT $http_str \\\n",
    "     -H \"accept: application/json\" \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"path\":\"nvidia/med/clara_train_deepgrow_aiaa_inference_only\",\"version\":\"1\"}'\n",
    "```\n",
    "```\n",
    "http_str=\"http://127.0.0.1:\"+AIAA_PORT+\"/admin/model/clara_ct_seg_spleen\"\n",
    "!curl -X PUT $http_str \\\n",
    "     -H \"accept: application/json\" \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"path\":\"nvidia/med/clara_ct_seg_spleen\",\"version\":\"1\"}'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 4. AIAA Clients \n",
    "\n",
    "AIAA server can connect to any client that implements the APIs found [here](https://github.com/NVIDIA/ai-assisted-annotation-client\n",
    "). \n",
    "NVIDIA has already implemented these APIs for a number of open source viewers as:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 4.1. [3D Slicer](https://www.slicer.org/)\n",
    "\n",
    "In order to use slicer you should: \n",
    "1. Install and setup slicer 3d following steps [here](https://github.com/NVIDIA/ai-assisted-annotation-client/tree/master/slicer-plugin)\n",
    "    1. Download and install recent 3D Slicer Preview Release (4.13.x) from [here](http://download.slicer.org/).    \n",
    "    2. Start 3D Slicer and open the Extension manager\n",
    "2. Install MonaiLabel extension (in Active Learning category), wait for the installation to complete, and click Restart\n",
    "3. Configure plugin. Add the `server address` location. \n",
    "   <br><img src=\"screenShots/SlicerConfig.png\" alt=\"Drawing\" style=\"height: 400px;\"/>\n",
    "4. You should load a volume and start trying the spleen and deep grow model as shown below\n",
    "     \n",
    "<br><img src=\"screenShots/Slicer.png\" alt=\"Drawing\" style=\"height: 400px;\"/><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 4.2. [MITK](https://www.mitk.org/wiki/The_Medical_Imaging_Interaction_Toolkit_(MITK))\n",
    "MITK is another viewer that you can use with AIAA. \n",
    "You can download and install it [here](http://mitk.org/wiki/Downloads). \n",
    "Please make sure you install the release with nvidia AIAA.<br>\n",
    "_Note_: Deep grow is not enabled yet in MITK \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 4.3. [OHIF](https://docs.ohif.org/)\n",
    "We have integrated AIAA with OHIF as a plugin, This has also been adapted in to XNAT. \n",
    "Plugin code can be found as a [branch of OHIF github](https://github.com/SachidanandAlle/Viewers). \n",
    "\n",
    "For more on how to use OHIF please see [OHIF Notebook](AIAAwOHIF.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 5. Delete Models from AIAA server  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# if you need to change the model name \n",
    "#modelName=\"Deepgrow3DV4EA\"\n",
    "!AIAA delete $modelName\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Or use the http API\n",
    "```\n",
    "http_str='\"http://127.0.0.1:'+AIAA_PORT+'/admin/model/'+modelName+'\"'\n",
    "!curl -X DELETE $http_str\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# 6. Stop AIAA server\n",
    "In order to stop the AIAA server you can run cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!AIAA stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "However, this will **not free up your gpu memory** \n",
    "since we are using **triton which is running in another container.**\n",
    "In order to release the gpu memory you would need to either stop the triton container, \n",
    "or delete the models from the triton model directory `/claraDevDay/AIAA/workspace/triton_models/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!mkdir $AIAA_ROOT/triton_models_full\n",
    "#!mv $AIAA_ROOT/triton_models_full_back/* $AIAA_ROOT/triton_models_full/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Next steps\n",
    "You should now train deepgrow yourself using \n",
    "[Train Deepgrow Notebook (2D and 3D)](AIAA/DeepGrow.ipynb) <span style=\"color:red\">(New in V4)</span>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": "<!--- SPDX-License-Identifier: Apache-2.0 -->\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
