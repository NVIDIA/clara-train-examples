{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "# AI Assisted Annotation \n\nManual annotation is slow, tediousÂ and costly. Faster labeling of 3D volumes using AI annotation models accelerates this process. Clara Train offers an AIAA API that easily integrates into common medical imaging viewers\n\u003cbr\u003e\u003cimg src\u003d\"screenShots/AIAASpeedup.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e\n\nAIAA is based on a server client model as shown below \n\u003cbr\u003e\u003cimg src\u003d\"screenShots/AIAAClientServer.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "By the end of this notebook you will be able to:\n",
        "- Start AIAA server \n",
        "- Load a deep grow model\n",
        "- Annotate using deep grow \n",
        "- Load your model and use it for annotations  \n",
        "- Stop AIAA server\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "## Prerequisites\n",
        "- Nvidia GPU with 8Gb of memory   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "### Resources\nIt might be helpful to watch the GTC Digital 2021 talk on Clara Train SDK\n- [Clara Train 4.0 - 101 Getting Started [SE2688]](https://www.nvidia.com/en-us/on-demand/session/gtcspring21-se2688/) \n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "# Lets get started"
    },
    {
      "cell_type": "markdown",
      "source": "To interact with AIAA from the command line you should use the AIAA as `AIAA -h`. \nThis would show you all commands as shown below\n```\nUsage: AIAA [-h] {start,stop,status,list,load,delete} ...\n\ncommands:\n  start   Start AIAA Server\n          AIAA start -h\n  stop    Stop AIAA Server\n  status  Check if AIAA Server is running\n  list    List all models loaded in AIAA\n  logs    Fetch AIAA Logs if server is running \u003clines\u003e\n  load    Load a model to AIAA using one of the sources {ngc|mmar|zip|config}\n          sources:\n            ngc      Load model from NGC\n                     AIAA load \u003cmodel\u003e ngc \u003cpath\u003e \u003cversion\u003e\n            mmar     Load model from MMAR Folder\n                     AIAA load \u003cmodel\u003e mmar \u003cpath\u003e\n            zip      Load model from ZIP Archive\n                     AIAA load \u003cmodel\u003e zip \u003cpath\u003e\n            config   Load model using AIAA Config and Model saved file\n                     AIAA load \u003cmodel\u003e config \u003caiaa_config\u003e \u003csaved_model\u003e\n            pipeline Load pipeline (as vitual model) using AIAA Config\n                     AIAA load \u003cmodel\u003e config \u003caiaa_config\u003e\n  delete  Delete a model from AIAA\n          AIAA delete \u003cmodel\u003e\n```",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Before we get started let us check that we have an NVIDIA GPU available in the docker by running the cell below",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# following command should show all gpus available \n!nvidia-smi",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "\n# 1. Start AIAA server\nFirst lets set up AIAA path and change some permissions "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "AIAA_ROOT\u003d\"/claraDevDay/AIAA/workspace/\"\nAIAA_PORT\u003d\"5000\"\n!mkdir -p $AIAA_ROOT\n!chmod 777 $AIAA_ROOT\nprint (\"AIAA_ROOT is set to \",AIAA_ROOT)\n"
    },
    {
      "cell_type": "markdown",
      "source": "##  1.1 AIAA Server with AIAA backend \nFor simple POC or getting started with AIAA you could use the AIAA backend which is simpler to setup.\nFor performance, we recommend you use triton as in the section below\n\nUnfortunately, Jupyter cells can\u0027t run a command as background.\nSo you would need to run one of the commands below from a terminal ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# start AIAA with AIAA backend  \n#AIAA start -w /claraDevDay/AIAA/workspace/ --engine AIAA \u0026\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "##  1.2 AIAA Server with Triton BackEnd \nStarting V4.0 Triton server was moved out of the clara train container. \nIn order to use Triton as the AIAA backend, you should use `startClaraTrainNoteBooks.sh`. \nThe script uses docker-compose to start both the clara train container and triton container, \nwhile connected them through the docker internal network. \nYou could also start AIAA server without triton using the AIAA backend option.\n\nUnfortunately, Jupyter cells can\u0027t run a command as background.\nSo you would need to run one of the commands below from a terminal ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# start AIAA with triton \n#AIAA start -b -w $AIAA_ROOT --engine TRITON --triton_ip tritonserver \u0026\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "# 2 Check on AIAA Server "
    },
    {
      "cell_type": "markdown",
      "source": "## 2.1 using CLI\nYou should check on the AIAA status",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!AIAA status   ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "You can also get the last 15 lines of the logs use",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!AIAA logs 15 ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "You can then easily filter on errors as  ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!AIAA logs |grep errors",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "To list models you can run ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!AIAA list | grep name",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!AIAA list",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n### 2.2 Using Browser\nYou can also check on the AIAA server using your browser by checking:\n- Main url `http://localhost:5000/` \u003cbr\u003e\n- APIS to list, upload, delete models `http://localhost:5000/docs/`\n- Check logs `http://localhost:5000/logs`\n- List available models `http://localhost:5000/v1/models/` \n ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 2.3 (For advanced users) Using curl commands\nYou can also use curl command to:\n- check on gpus ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "http_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/monailabel/logs/gpu\"\n!curl -X GET $http_str -H \"accept: application/json\" ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "- List models",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "http_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/v1/models\"\n!curl -X GET $http_str -H \"accept: application/json\"",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": "#  3. Load models in AIAA Server. \nFor this notebook we can download models from [NGC](). Models on NGC are either:\n- Annotation Models \u003cbr\u003e\n[Deep Extreme Cut: From Extreme Points to Object Segmentation](https://arxiv.org/abs/1711.09081)\n\u003cbr\u003e\u003cimg src\u003d\"screenShots/AIAAAnnotation.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e\n\n- Segmentation Models\n- DeepGrow MMAR \nThis is an interactive model to get you started with annotation. \nCNN takes in single channel (image) + use single click for foreground or background location then produces the segmentation. \nIt is based on [Interactive segmentation of medical images through\nfully convolution neural networks](https://arxiv.org/pdf/1903.08205.pdf)\n\u003cbr\u003e\u003cimg src\u003d\"screenShots/AIAADeepGrow.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "## 3.0 Loading options\nIn order to load a model to AIAA we will use the AIAA cli as "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "! AIAA load -h",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "This will show you options which allows to load from ngc or a local MMAR or a local zip file, etc \n```\nroot@claratrain:/claraDevDay/AIAA# AIAA load -h\nLoading Model: -h\nUsage: AIAA load \u003cmodel\u003e {ngc|mmar|zip|config|pipeline} ...\n```",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 3.1 Load model trained from Getting started notebook\nIn order to load model trained in the getting started notebook you can run",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "modelName\u003d\"Test\"\nmodelFolderPath\u003d\"/claraDevDay/GettingStarted/models/config_train_Unet/model.ts\"\nconfigFolderPath\u003d\"/claraDevDay/GettingStarted/config/config_aiaa.json\"\n!AIAA load $modelName config $configFolderPath $modelFolderPath \n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 3.2 Using NGC CLI to download model from NGC\nYou can see a [list of available pre-trained models](https://ngc.nvidia.com/containers/nvidia:clara-train-sdk) on NGC. \nYou can also use `ngc registry model list nvidia/med/clara_*` to get a list of models.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!ngc registry model list nvidia/med/clara_pt*",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "# you can then filter on the model you want so it is easier to grab the repository path \n!ngc registry model list nvidia/med/*spleen_ct_segment*\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": "The cell below will list the deepgrow models"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "# you can then filter on the model you want so it is easier to grab the repository path \n!ngc registry model list nvidia/med/*clara_pt_deepgrow*"
    },
    {
      "cell_type": "markdown",
      "source": "The cell below will download the the deep grow model from NGC and load it to AIAA",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "!AIAA load deepgrow3d ngc \"nvidia/med/clara_pt_deepgrow_3d_annotation\" 1\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "The following cell will download the spleen model and load it into the AIAA server"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "# !AIAA load spleen_seg ngc \"nvidia/med/clara_pt_spleen_ct_segmentation\" 1\n!curl -X PUT \"http://127.0.0.1:5000/admin/model/clara_pt_spleen_ct_segmentation\" -F \u0027ngc\u003d{\"path\":\"nvidia/med/clara_pt_spleen_ct_segmentation\",\"version\":\"1\"}\u0027"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# !AIAA load liver_seg ngc \"nvidia/med/clara_pt_liver_and_tumor_ct_segmentation\" 1\n!curl -X PUT \"http://127.0.0.1:5000/admin/model/clara_pt_liver_and_tumor_ct_segmentation\" -F \u0027ngc\u003d{\"path\":\"nvidia/med/clara_pt_liver_and_tumor_ct_segmentation\",\"version\":\"1\"}\u0027",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "## 3.3 Manually Download model from NGC \nIf you have a private registry or have early access (EA) to nvidia\u0027s developer program, \nyou can manually downloaded the MMAR form NGC by clicking the ... button as shown below\n\u003cbr\u003e\u003cimg src\u003d\"screenShots/DownloadFromNGC.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e\n"
    },
    {
      "cell_type": "markdown",
      "source": "**You should download zip file to /claraDevDay/AIAA/DownloadsFromNGC/**\n\nFor example if you downloaded the covid segmentation model and named the file `CovidsegModel.zip`, \nthen you can run cell below to load up the zipped file to AIAA server \n\n**Please make sure the zip file directly contains the mmar folder structure \nError will occur if the zipped file contains a folder before the mmar**",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\ndownloadedFile\u003d\"CovidsegModel.zip\"\n\ndownloadDir\u003dAIAA_ROOT+\"../DownloadsFromNGC/\"\nmodelName\u003ddownloadedFile[:-4]\nzipmodelPath\u003ddownloadDir+downloadedFile\n!AIAA load $modelName zip $zipmodelPath\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "## 3.3.1 (optional) In case of error with zip file\nIn case the zip files container an extra directory, you can unzip using cell below\nZip file should have the MMAR structure. \nCell below would unzip the MMAR then upload it to AIAA server \n```\ndownloadedFile\u003d\"deepgrow_3d.zip\"\n\ndownloadDir\u003dAIAA_ROOT+\"../DownloadsFromNGC/\"\nmodelName\u003ddownloadedFile[:-4]\nmodelFolderPath\u003ddownloadDir+modelName\n\n%cd $downloadDir\n!unzip $downloadedFile -d $modelName\n# then you should load the mmar to AIAA \n\n!AIAA load $modelName mmar $modelFolderPath\n```"
    },
    {
      "cell_type": "markdown",
      "source": "## 3.4 load a pipeline created from multiple models into AIAA\nAIAA now supports the concept of a pipelines which triggers multiple models one at a time.\ncell below creates a pipeline out of 3D deepgrow which gets new seed points for multiple runs of deepgrow 2D.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "modelName\u003d\"GA_Deepgrow_Pipeline\"\nconfigFolderPath\u003dAIAA_ROOT+\"../Deepgrow2D3D_pipeline.json\"\n \n!AIAA load $modelName pipeline $configFolderPath \n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "\n## 3.5 Check for models loaded into AIAA\nLet us check the server and check that the model is uploaded. \nCell below would list models loaded by the AIAA server "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "!AIAA list |grep name  "
    },
    {
      "cell_type": "markdown",
      "source": "## 3.6 (Optional for advanced users) Loading models using curl commands\nFor advanced users or programmers integrating with AIAA, \nThey could do the above task using curl commands as:  \n\n```\nhttp_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/admin/model/\"+modelName\nconf_str\u003d\"config\u003d@\"+downloadDir+modelName+\"/config/config_aiaa.json;type\u003dapplication/json\"\ndataArg\u003d\"data\u003d@\"+downloadDir+modelName+\"/models/model.ts\"\ncmd\u003d\u0027curl -X PUT \"\u0027+http_str +\u0027\" -F \"\u0027+conf_str +\u0027\" -F \"\u0027+dataArg +\u0027\"\u0027\n```\nCommand below would download from NGC and load the deep grow and spleen segmentation model to AIAA\n```\n# model name from NGC is clara_train_deepgrow_aiaa_inference_only\nhttp_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/admin/model/clara_deepgrow\"\n!curl -X PUT $http_str \\\n     -H \"accept: application/json\" \\\n     -H \"Content-Type: application/json\" \\\n     -d \u0027{\"path\":\"nvidia/med/clara_train_deepgrow_aiaa_inference_only\",\"version\":\"1\"}\u0027\n```\n```\nhttp_str\u003d\"http://127.0.0.1:\"+AIAA_PORT+\"/admin/model/clara_ct_seg_spleen\"\n!curl -X PUT $http_str \\\n     -H \"accept: application/json\" \\\n     -H \"Content-Type: application/json\" \\\n     -d \u0027{\"path\":\"nvidia/med/clara_ct_seg_spleen\",\"version\":\"1\"}\u0027\n```\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "# 4. AIAA Clients \n\nAIAA server can connect to any client that implements the APIs found [here](https://github.com/NVIDIA/ai-assisted-annotation-client\n). \nNVIDIA has already implemented these APIs for a number of open source viewers as:\n"
    },
    {
      "cell_type": "markdown",
      "source": "## 4.1. [3D Slicer](https://www.slicer.org/)\n\nIn order to use slicer you should: \n1. Install and setup slicer 3d following steps [here](https://github.com/NVIDIA/ai-assisted-annotation-client/tree/master/slicer-plugin)\n    1. Download and install recent 3D Slicer Preview Release (4.13.x) from [here](http://download.slicer.org/).    \n    2. Start 3D Slicer and open the Extension manager\n2. Install MonaiLabel extension (in Active Learning category), wait for the installation to complete, and click Restart\n3. Configure plugin. Add the `server address` location. \n   \u003cbr\u003e\u003cimg src\u003d\"screenShots/SlicerConfig.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\n4. You should load a volume and start trying the spleen and deep grow model as shown below\n     \n\u003cbr\u003e\u003cimg src\u003d\"screenShots/Slicer.png\" alt\u003d\"Drawing\" style\u003d\"height: 400px;\"/\u003e\u003cbr\u003e",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 4.2. [MITK](https://www.mitk.org/wiki/The_Medical_Imaging_Interaction_Toolkit_(MITK))\nMITK is another viewer that you can use with AIAA. \nYou can download and install it [here](http://mitk.org/wiki/Downloads). \nPlease make sure you install the release with nvidia AIAA.\u003cbr\u003e\n_Note_: Deep grow is not enabled yet in MITK \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 4.3. [OHIF](https://docs.ohif.org/)\nWe have integrated AIAA with OHIF as a plugin, This has also been adapted in to XNAT. \nPlugin code can be found as a [branch of OHIF github](https://github.com/SachidanandAlle/Viewers). \n\nFor more on how to use OHIF please see [OHIF Notebook](AIAAwOHIF.ipynb)",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 5. Delete Models from AIAA server  ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# if you need to change the model name \n#modelName\u003d\"Deepgrow3DV4EA\"\n!AIAA delete $modelName\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Or use the http API\n```\nhttp_str\u003d\u0027\"http://127.0.0.1:\u0027+AIAA_PORT+\u0027/admin/model/\u0027+modelName+\u0027\"\u0027\n!curl -X DELETE $http_str\n```\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 6. Stop AIAA server\nIn order to stop the AIAA server you can run cell below.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "!AIAA stop"
    },
    {
      "cell_type": "markdown",
      "source": "\nHowever, this will **not free up your gpu memory** \nsince we are using **triton which is running in another container.**\nIn order to release the gpu memory you would need to either stop the triton container, \nor delete the models from the triton model directory `/claraDevDay/AIAA/workspace/triton_models/`",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "#!mkdir $AIAA_ROOT/triton_models_full\n#!mv $AIAA_ROOT/triton_models_full_back/* $AIAA_ROOT/triton_models_full/\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Next steps\nYou should now train deepgrow yourself using \n[Train Deepgrow Notebook (2D and 3D)](AIAA/DeepGrow.ipynb) \u003cspan style\u003d\"color:red\"\u003e(New in V4)\u003c/span\u003e\n\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "\u003c!--- SPDX-License-Identifier: Apache-2.0 --\u003e\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}